{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Understanding Classification Metrics in Scikit - Learn\n",
    "--- "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   actual_label  model_RF  model_LR\n",
       "0             1  0.639816  0.531904\n",
       "1             0  0.490993  0.414496\n",
       "2             1  0.623815  0.569883\n",
       "3             1  0.506616  0.443674\n",
       "4             0  0.418302  0.369532"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_label</th>\n      <th>model_RF</th>\n      <th>model_LR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.639816</td>\n      <td>0.531904</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.490993</td>\n      <td>0.414496</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.623815</td>\n      <td>0.569883</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.506616</td>\n      <td>0.443674</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.418302</td>\n      <td>0.369532</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/Users/qab/Desktop/data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   actual_label  model_RF  model_LR  predicted_RF  predicted_LR\n",
       "0             1  0.639816  0.531904             1             1\n",
       "1             0  0.490993  0.414496             0             0\n",
       "2             1  0.623815  0.569883             1             1\n",
       "3             1  0.506616  0.443674             1             0\n",
       "4             0  0.418302  0.369532             0             0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_label</th>\n      <th>model_RF</th>\n      <th>model_LR</th>\n      <th>predicted_RF</th>\n      <th>predicted_LR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.639816</td>\n      <td>0.531904</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.490993</td>\n      <td>0.414496</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.623815</td>\n      <td>0.569883</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.506616</td>\n      <td>0.443674</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.418302</td>\n      <td>0.369532</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "data['predicted_RF'] = (data.model_RF >= 0.5).astype('int')\n",
    "data['predicted_LR'] = (data.model_LR >= 0.5).astype('int')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5519, 2360],\n",
       "       [2832, 5047]])"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data.actual_label.values, data.predicted_RF.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_TP (y_true, y_pred):\n",
    "    return sum((y_true == 1) & (y_pred == 1))\n",
    "\n",
    "def find_FN (y_true, y_pred):\n",
    "    return sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "def find_TN (y_true, y_pred):\n",
    "    return sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "def find_FP (y_true, y_pred):\n",
    "    return sum((y_true == 0) & (y_pred == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5047"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "find_TP(data.actual_label, data.predicted_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2832"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "find_FN(data.actual_label, data.predicted_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5519"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "find_TN(data.actual_label, data.predicted_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2360"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "find_FP(data.actual_label, data.predicted_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TP: 5047\nFN: 2832\nFP: 2360\nTN: 5519\n"
     ]
    }
   ],
   "source": [
    "print('TP:',find_TP(data.actual_label.values, data.predicted_RF.values))\n",
    "print('FN:',find_FN(data.actual_label.values, data.predicted_RF.values))\n",
    "print('FP:',find_FP(data.actual_label.values, data.predicted_RF.values))\n",
    "print('TN:',find_TN(data.actual_label.values, data.predicted_RF.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conf_matrix_values(y_true, y_pred):\n",
    "    TP = find_TP(y_true, y_pred)\n",
    "    FN = find_FN(y_true, y_pred)\n",
    "    FP = find_FP(y_true, y_pred)\n",
    "    TN = find_TN(y_true, y_pred)\n",
    "    return TP, TN, FN, FP\n",
    "\n",
    "def my_confusion_matrix(y_true, y_pred):\n",
    "    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)\n",
    "    return np.array([[TN, FP], [FN, TP]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2360, 5519],\n",
       "       [2832, 5047]])"
      ]
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "source": [
    "my_confusion_matrix(data.actual_label.values, data.predicted_RF.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5047, 5519, 2832, 2360)"
      ]
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "source": [
    "find_conf_matrix_values(data.actual_label, data.predicted_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "my_confusion_matrix() is not correct for RF",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-5011eb58ee7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m assert  np.array_equal(my_confusion_matrix(data.actual_label.values, data.predicted_RF.values),\\\n\u001b[0;32m----> 2\u001b[0;31m                        confusion_matrix(data.actual_label.values, data.predicted_RF.values) ), 'my_confusion_matrix() is not correct for RF'\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m assert  np.array_equal(my_confusion_matrix(data.actual_label.values, data.predicted_LR.values),\\\n\u001b[1;32m      5\u001b[0m                        confusion_matrix(data.actual_label.values, data.predicted_LR.values) ), 'my_confusion_matrix() is not correct for LR'\n",
      "\u001b[0;31mAssertionError\u001b[0m: my_confusion_matrix() is not correct for RF"
     ]
    }
   ],
   "source": [
    "assert  np.array_equal(my_confusion_matrix(data.actual_label.values, data.predicted_RF.values),\\\n",
    "                       confusion_matrix(data.actual_label.values, data.predicted_RF.values) ), 'my_confusion_matrix() is not correct for RF'\n",
    "\n",
    "assert  np.array_equal(my_confusion_matrix(data.actual_label.values, data.predicted_LR.values),\\\n",
    "                       confusion_matrix(data.actual_label.values, data.predicted_LR.values) ), 'my_confusion_matrix() is not correct for LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6705165630156111"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(data.actual_label.values, data.predicted_RF.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy_score(y_true, y_pred):\n",
    "    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy RF: 0.671\nAccuracy LR: 0.616\n"
     ]
    }
   ],
   "source": [
    "assert my_accuracy_score(data.actual_label.values, data.predicted_RF.values) == accuracy_score(data.actual_label.values, data.predicted_RF.values), 'my_accuracy_score failed on RF'\n",
    "assert my_accuracy_score(data.actual_label.values, data.predicted_LR.values) == accuracy_score(data.actual_label.values, data.predicted_LR.values), 'my_accuracy_score failed on LR'\n",
    "print('Accuracy RF: %.3f'%(my_accuracy_score(data.actual_label.values, data.predicted_RF.values)))\n",
    "print('Accuracy LR: %.3f'%(my_accuracy_score(data.actual_label.values, data.predicted_LR.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}